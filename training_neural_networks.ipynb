{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Neural Networks\n",
    "# including helper functionalities\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def test_network(net, trainloader):\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # Create Variables for the inputs and targets\n",
    "    inputs = Variable(images)\n",
    "    targets = Variable(images)\n",
    "\n",
    "    # Clear the gradients from all Variables\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass, then backward pass, then update weights\n",
    "    output = net.forward(inputs)\n",
    "    loss = criterion(output, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def view_recon(img, recon):\n",
    "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
    "        reconstruction also a PyTorch Tensor\n",
    "    '''\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
    "    axes[0].imshow(img.numpy().squeeze())\n",
    "    axes[1].imshow(recon.data.numpy().squeeze())\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "        ax.set_adjustable('box-forced')\n",
    "\n",
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "                               ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/PyTorchChallenge/MNIST_dara/', download = True, train=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3094, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10)\n",
    "                     )\n",
    "# define the loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our Data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Flatten the images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "\n",
    "# Calculate the loss with the logits and labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2961, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "## Building a feed forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim = 1)\n",
    "                     )\n",
    "# define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
      "        [ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
      "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
      "        ...,\n",
      "        [-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n",
      "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
      "        [-0.0028, -0.0028, -0.0028,  ..., -0.0028, -0.0028, -0.0028]])\n"
     ]
    }
   ],
   "source": [
    "# autograd\n",
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "#optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0055, -0.0175, -0.0210,  ...,  0.0220,  0.0062, -0.0016],\n",
      "        [-0.0303,  0.0034,  0.0050,  ..., -0.0109,  0.0087, -0.0248],\n",
      "        [ 0.0083,  0.0217, -0.0159,  ...,  0.0086,  0.0199, -0.0267],\n",
      "        ...,\n",
      "        [-0.0050, -0.0163, -0.0170,  ...,  0.0330,  0.0341, -0.0301],\n",
      "        [ 0.0178,  0.0159,  0.0215,  ...,  0.0104, -0.0288,  0.0172],\n",
      "        [ 0.0312,  0.0281, -0.0270,  ..., -0.0190, -0.0058, -0.0338]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003],\n",
      "        ...,\n",
      "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        [-0.0052, -0.0052, -0.0052,  ..., -0.0052, -0.0052, -0.0052]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 0.0055, -0.0175, -0.0210,  ...,  0.0220,  0.0062, -0.0016],\n",
      "        [-0.0303,  0.0034,  0.0050,  ..., -0.0109,  0.0087, -0.0248],\n",
      "        [ 0.0083,  0.0217, -0.0159,  ...,  0.0086,  0.0199, -0.0267],\n",
      "        ...,\n",
      "        [-0.0050, -0.0163, -0.0170,  ...,  0.0330,  0.0340, -0.0301],\n",
      "        [ 0.0178,  0.0159,  0.0215,  ...,  0.0104, -0.0288,  0.0172],\n",
      "        [ 0.0312,  0.0281, -0.0270,  ..., -0.0189, -0.0058, -0.0337]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Take an update step and few the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0318572866573517\n",
      "Training loss: 0.3820164872289721\n",
      "Training loss: 0.3238645542277964\n",
      "Training loss: 0.292913393488825\n",
      "Training loss: 0.26850275350595587\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim = 1)\n",
    "                    )\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# with the network trained, we can check out its predictions\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "\n",
    "# turn of gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "    \n",
    "# output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "view_classify(img.view(1,28,28), ps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
